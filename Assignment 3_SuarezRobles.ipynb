{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set? Answer: Another optional parameter is tunning the n_stimators for RF and GBR however I decided to use the default.\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7555804-0b0e-4413-8918-0e0a852dc27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "info = {'index': ['DT','RF','GB'], 'model': [], 'MSE Training accuracy': [], 'MSE Validation accuracy': [], \n",
    "        'R2 Training accuracy' : [], 'R2 Validation accuracy': []}\n",
    "\n",
    "# Another optional parameter is tunning the n_stimators for RF and GBR however I decided to use the default.\n",
    "info['model'].append(DecisionTreeRegressor(max_depth = 5, random_state = 0))     # tree model\n",
    "info['model'].append(RandomForestRegressor(max_depth = 5, random_state = 0))     # forest model\n",
    "info['model'].append(GradientBoostingRegressor(max_depth = 5, random_state = 0)) # gbr model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8156d4-cd49-459c-aedb-f4178bd43380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "for model in info['model']:\n",
    "    tree_scores = cross_validate(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    info['MSE Training accuracy'].append(-1 * tree_scores['train_score'].mean()) \n",
    "    info['MSE Validation accuracy'].append(-1 * tree_scores['test_score'].mean())  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Training accuracy</th>\n",
       "      <th>MSE Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>47.280</td>\n",
       "      <td>73.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>29.576</td>\n",
       "      <td>45.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>3.379</td>\n",
       "      <td>22.820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSE Training accuracy  MSE Validation accuracy\n",
       "DT                 47.280                   73.447\n",
       "RF                 29.576                   45.052\n",
       "GB                  3.379                   22.820"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'MSE Training accuracy': info['MSE Training accuracy'],\n",
    "    'MSE Validation accuracy': info['MSE Validation accuracy']\n",
    "}, index=info['index'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2 Training accuracy</th>\n",
       "      <th>R2 Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R2 Training accuracy  R2 Validation accuracy\n",
       "DT                 0.834                   0.739\n",
       "RF                 0.897                   0.841\n",
       "GB                 0.988                   0.919"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "for model in info['model']:\n",
    "    tree_scores = cross_validate(model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "    info['R2 Training accuracy'].append(tree_scores['train_score'].mean()) \n",
    "    info['R2 Validation accuracy'].append(tree_scores['test_score'].mean())  \n",
    "    \n",
    "\n",
    "results['R2 Training accuracy'] = info['R2 Training accuracy']\n",
    "results['R2 Validation accuracy'] = info['R2 Validation accuracy']\n",
    "results[['R2 Training accuracy', 'R2 Validation accuracy']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08e831-5e0e-41a6-8d87-cebdd3dc2117",
   "metadata": {
    "tags": []
   },
   "source": [
    "Results using LinearRegression in the previous assigment:\n",
    "\n",
    "|               | Training accuracy | Validation accuracy |\n",
    "|---------------|-------------------|---------------------|\n",
    "| MSE           | 111.358439        | 95.904136           |\n",
    "| R2 score      | 0.610823          | 0.623414            |\n",
    "\n",
    "Answers:\n",
    "1. When compared to linear regression's MSE values 111.35 and 95.90 for training and validation accuracy. DT reduced the values to 47 and 73, RF further lower it to 29 and finally GB had the best MSE with 3 and 22 respectively. This means that overall the distance or error between the predicted values and the actual values was reduced the more complex model we use. Once again this is demonstrated when comparing R2 values, the R2 training and validation accuracy increased from .61 and .62 in linear regression to up to .988 and .919 using gradient booster. However notice that overall the R2 training accuracy for DT, RF and GB is high when compared to their validation accuracy thus we might benefit from some parameter tunning as we might have be slightly overfitting. But this is just my guess based on the numbers.\n",
    "\n",
    "1. For this dataset I would choose gradient booster regression because it offered the lowest MSE validation accuracy and the highest R2 validation accuracy. However in other scenario I might have chosen random forests because they require less careful parameter tunning.\n",
    "\n",
    "1. Something that I mentioned in a comment above is that in the case of RF and GB I would test (tune) different numbers of stimators. For decision tres I could tune max_depth, max_leaf_nodes or min_samples_leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "I completed each step in ascending order (following the same order in which each question or code implementation problem appears). Although for this exercise I had to go back and make changes a few times after I realised I made mistakes. \n",
    "\n",
    "I sourced my code mainly copyng, pasting and then editing the code from the example notebooks in d2l. \n",
    "\n",
    "Yes I use chatgpt when I get frustraded of certain part of my code not working. Although I use chatgpt as a last resort and try to solve any issues on my own first. For this excercise I was getting amazing MSE scores when compared to linear regression and terrible R2 scores. So for me this didn't make any sense since lower MSE leads to higher R2 and because I coudn't find the reason why this happened I asked chatgpt. Chatgpt agreed with me that it din't make sense and pointing the reasons as: \"Error in Calculation or Reporting, Scale of Data, Variability in the Baseline Model or Overfitting\". Fairly enough I double checked my code and I was using cross validate with X and y instead of X_train and y_train.\n",
    "\n",
    "I didn't have any bigger challenges besides the one I just mentioned. I think Decision trees, Random forests and Gradient boosting models are faily easy to understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /Users/oakisr/anaconda3/envs/ensf-ml/lib/python3.11/site-packages (0.0.2)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608783c0-ddb2-4b56-9a70-d181299b525c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (178, 13)\n",
      "y shape: (178,)\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# wine.data.targets returns a df with a single column thus I extract it a a data series \n",
    "X, y = wine.data.features, wine.data.targets['class']\n",
    "print(f\"X shape: {X.shape}\\ny shape: {y.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malicacid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>0D280_0D315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0    14.23       1.71  2.43               15.6        127           2.80   \n",
       "1    13.20       1.78  2.14               11.2        100           2.65   \n",
       "2    13.16       2.36  2.67               18.6        101           2.80   \n",
       "3    14.37       1.95  2.50               16.8        113           3.85   \n",
       "4    13.24       2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   0D280_0D315_of_diluted_wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alcohol                         0\n",
       "Malicacid                       0\n",
       "Ash                             0\n",
       "Alcalinity_of_ash               0\n",
       "Magnesium                       0\n",
       "Total_phenols                   0\n",
       "Flavanoids                      0\n",
       "Nonflavanoid_phenols            0\n",
       "Proanthocyanins                 0\n",
       "Color_intensity                 0\n",
       "Hue                             0\n",
       "0D280_0D315_of_diluted_wines    0\n",
       "Proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0cef891-a681-45f1-a43d-759e3a11b9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0 has 59 samples\n",
      "Type 1 has 71 samples\n",
      "Type 2 has 48 samples\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print('\\n'.join([f\"Type {i} has {c} samples\" for i, c in enumerate(y.value_counts().sort_index())]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4fb6902-9c75-4919-b7cc-5aad919e6115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "info = {'index': ['SVC','DTC'], 'Training accuracy': [], 'Validation accuracy': []}\n",
    "\n",
    "info['model'] = [SVC(random_state = 0), DecisionTreeClassifier(max_depth = 3, random_state = 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9365116a-7bb0-4850-9161-beb5a2bbea5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "for model in info['model']:\n",
    "    model_scores = cross_validate(model, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    info['Training accuracy'].append(model_scores['train_score'].mean())\n",
    "    info['Validation accuracy'].append(model_scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data size</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>(133, 13)</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTC</th>\n",
       "      <td>(133, 13)</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data size  Training accuracy  Validation accuracy\n",
       "SVC  (133, 13)              0.680                0.677\n",
       "DTC  (133, 13)              0.994                0.894"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "results = pd.DataFrame({'Data size': [X_train.shape, X_train.shape],\n",
    "                        'Training accuracy': info['Training accuracy'],\n",
    "                        'Validation accuracy': info['Validation accuracy']\n",
    "}, index = info['index'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Implement best model\n",
    "DTC_trained = info['model'][1].fit(X_train, y_train)\n",
    "y_pred = DTC_trained.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(170.97222222222223, 0.5, 'true value')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False, cmap='coolwarm')\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>type 1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.933</td>\n",
       "      <td>16.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type 2</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.930</td>\n",
       "      <td>21.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type 3</th>\n",
       "      <td>0.889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.941</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.935</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.933</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "type 1            1.000   0.875     0.933   16.000\n",
       "type 2            0.909   0.952     0.930   21.000\n",
       "type 3            0.889   1.000     0.941    8.000\n",
       "accuracy          0.933   0.933     0.933    0.933\n",
       "macro avg         0.933   0.942     0.935   45.000\n",
       "weighted avg      0.938   0.933     0.933   45.000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, target_names=[\"type 1\", \"type 2\", \"type 3\"], output_dict=True)\n",
    "pd.DataFrame(report_dict).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222609a7-1d3a-4997-828d-170368c25092",
   "metadata": {},
   "source": [
    "1. The SVC has low training an accuracy values 0.68 and 0.67 respectively. Although the both values are very closed together which means that overall SVC has low bias and it's \"good\" generalizing new unseen data. DTC performed much better increasing both training an accuracy scores to 0.99 and 0.89 respectvively which is around 21% higher when compared to SVC. However there is a significant gap of around 10% between DTC training and validation accuracy meaning we might be overfitting.\n",
    "\n",
    "1. SVC did not perform as well or just well primarily because SVC is sensitive to the scale of the features and benefits from normalization however our data is in different scales for example the column Nonflavanoid_phenols contains values in the order of decimal places like 0.24 while magnesium values are in hundreds, etc. On the other hand DTC is not affecting by the scaling. Additionally SVC has the challenge to handle no-linearly separable data. Using the \"Kernel trick\" can make our model more powerful by transforming the data into a higher dimensional space where it can be more easily separable. Finally SVC also requires careful tunning of its parameters like C and gamma to obtain the best results. \n",
    "\n",
    "1. Only 3. If we look at the column wine type 1 we got 2 false positives that were actually wine type 0. And if we look at the row wine type 1 we got a false negative where the model classified as type 2.\n",
    "\n",
    "1. For a wine machine learning application I don't think maximizing one of them is more important than the other because classifying wine is not a life or death deal like predicting cancer where we prefer to maximime recall because we want to make sure sick patients are always treated. If I were a wine producer selling wine both low precision or low recall will lead to the same exact outcome of mislabeling wine and decieving costumers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "I completed each step following the same order in which each question or code implementation problem appears. And I sourced my code mainly copyng, pasting and then editing the code from the example notebooks in d2l and also from my own code I implemented to complete assigment 2 and the labs.\n",
    "\n",
    "Yes I use chatgpt to show me how to create a confusion matrix. Although I could have look at it in gooogle or in the notebooks. I also ask it what is a classification report because I had no idea what I was asked for. The precision, recall and f1, accuracy and support are concepts I understand although I am not sure what macro avg and weighted avg stand for. \n",
    "\n",
    "I didn't have any bigger challenges. I find so far classification models and its metrics are easier to understand than regression models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "1. In the lectures we saw that some machine learning models works better when we preprocess the data and apply scaling. This was demonstrated when comparing the validation score of 0.894 for decision trees for classification against 0.677 for support vectores for classification. Where the first one is not affected by the data scaling whereas the second one is highly sensitive.  \n",
    "\n",
    "1. We also discussed that Decision Trees tend to overfit the training data. This is observed in the results where the training accuracy of 0.994 is 11% higher than the validation accuracy of 0.894. And as it was mentioned during lecture Random forests are one way to address this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "I really like that in this assigment we compared the performance of different machine learning models. I think that is very useful to learn to identify the strengths and weakneses of each model and reflect on things we can tune or implemenent to increase the performance of our models.\n",
    "\n",
    "I still would like we were given at least half of the lab time to work on the assigments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.992\n",
      "Validation accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linearSVC = LinearSVC(max_iter=10000, dual=False)\n",
    "\n",
    "model_scores = cross_validate(linearSVC, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "print(f\"Training accuracy: {model_scores['train_score'].mean():.3f}\")\n",
    "print(f\"Validation accuracy: {model_scores['test_score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "LinearSVC made outstading improvements increasing the validation accuracy from 0.677 in SVC and 0.894 in DTC to 0.977. Thus LinearSVC a good fit for this dataset.\n",
    "\n",
    "Whereas SVC is vesatil and can handle both linear and non linear separable features, as well as allows us to choose from different kernerls. LinearSVC is an optimized algorithm for linear classification. Thus based on the results we can conclude that this dataset may have linearly separable features which LinearSVC is better able to capture when compared to the other two models.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
